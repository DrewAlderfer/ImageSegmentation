{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19812e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 23:13:00.906569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 23:13:00.970791: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from src.utils.classes import CategoricalDataGen\n",
    "from src.utils.funcs import *\n",
    "from src.utils.box_cutter import BoundingBox_Processor\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from matplotlib.animation import FuncAnimation, HTMLWriter, PillowWriter\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c58fdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01f872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%aimport src.utils.box_cutter\n",
    "%aimport src.utils.funcs\n",
    "%aimport src.utils.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e18efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 269 train images\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 55 val images\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 60 test images\n"
     ]
    }
   ],
   "source": [
    "data = init_COCO(\"./data/\", [\"train\", \"val\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae4d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "input_size = (1440, 1920)\n",
    "target_size = (512, 512)\n",
    "num_classes = 13\n",
    "\n",
    "def convert_points(b_x, output_size=(512, 384)):\n",
    "    adjX, adjY = output_size\n",
    "    adjustment = np.array([1920, 1440])\n",
    "    result = []\n",
    "    b_x = b_x / adjustment\n",
    "    b_x = tf.where(b_x > 0, b_x, 0).numpy()\n",
    "    b_x = tf.where(b_x < 1, b_x, 1).numpy()\n",
    "    box_tipped = np.sort(b_x.T, axis=-1)\n",
    "    box_tipped = box_tipped.T\n",
    "    max = box_tipped[-1:]\n",
    "    min = box_tipped[0:1]\n",
    "    w, h = np.squeeze(np.abs(np.diff(np.concatenate((max, min), axis=0).T, axis=-1)).T)\n",
    "    x, y = np.squeeze(min)\n",
    "    # result.append([y, x, h, w])  \n",
    "    return y, x, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7492fd0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on train data!\n",
      "screws_002.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 23:13:08.038079: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.040330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.040350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.042745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.042772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.042783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.654703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.654774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.654782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1701] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-01-04 23:13:08.654808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1026] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 23:13:08.654837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1614] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5359 MB memory:  -> device: 0, name: NVIDIA RTX A2000 8GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screws_003.png\n",
      "screws_004.png\n",
      "screws_005.png\n",
      "screws_007.png\n",
      "screws_008.png\n",
      "screws_009.png\n",
      "screws_011.png\n",
      "screws_012.png\n",
      "screws_013.png\n",
      "screws_014.png\n",
      "screws_016.png\n",
      "screws_018.png\n",
      "screws_019.png\n",
      "screws_020.png\n",
      "screws_021.png\n",
      "screws_024.png\n",
      "screws_025.png\n",
      "screws_026.png\n",
      "screws_028.png\n",
      "screws_029.png\n",
      "screws_030.png\n",
      "screws_031.png\n",
      "screws_032.png\n",
      "screws_033.png\n",
      "screws_034.png\n",
      "screws_035.png\n",
      "screws_036.png\n",
      "screws_037.png\n",
      "screws_038.png\n",
      "screws_039.png\n",
      "screws_040.png\n",
      "screws_041.png\n",
      "screws_043.png\n",
      "screws_047.png\n",
      "screws_048.png\n",
      "screws_049.png\n",
      "screws_050.png\n",
      "screws_052.png\n",
      "screws_053.png\n",
      "screws_054.png\n",
      "screws_055.png\n",
      "screws_057.png\n",
      "screws_060.png\n",
      "screws_061.png\n",
      "screws_062.png\n",
      "screws_063.png\n",
      "screws_066.png\n",
      "screws_067.png\n",
      "screws_068.png\n",
      "screws_069.png\n",
      "screws_070.png\n",
      "screws_071.png\n",
      "screws_072.png\n",
      "screws_073.png\n",
      "screws_074.png\n",
      "screws_075.png\n",
      "screws_076.png\n",
      "screws_077.png\n",
      "screws_080.png\n",
      "screws_081.png\n",
      "screws_082.png\n",
      "screws_083.png\n",
      "screws_084.png\n",
      "screws_085.png\n",
      "screws_086.png\n",
      "screws_087.png\n",
      "screws_088.png\n",
      "screws_090.png\n",
      "screws_091.png\n",
      "screws_092.png\n",
      "screws_093.png\n",
      "screws_094.png\n",
      "screws_095.png\n",
      "screws_097.png\n",
      "screws_100.png\n",
      "screws_101.png\n",
      "screws_103.png\n",
      "screws_104.png\n",
      "screws_107.png\n",
      "screws_109.png\n",
      "screws_112.png\n",
      "screws_113.png\n",
      "screws_114.png\n",
      "screws_115.png\n",
      "screws_116.png\n",
      "screws_117.png\n",
      "screws_118.png\n",
      "screws_119.png\n",
      "screws_120.png\n",
      "screws_121.png\n",
      "screws_122.png\n",
      "screws_123.png\n",
      "screws_124.png\n",
      "screws_125.png\n",
      "screws_127.png\n",
      "screws_128.png\n",
      "screws_132.png\n",
      "screws_133.png\n",
      "screws_134.png\n",
      "screws_135.png\n",
      "screws_137.png\n",
      "screws_138.png\n",
      "screws_139.png\n",
      "screws_141.png\n",
      "screws_143.png\n",
      "screws_144.png\n",
      "screws_146.png\n",
      "screws_147.png\n",
      "screws_148.png\n",
      "screws_149.png\n",
      "screws_150.png\n",
      "screws_153.png\n",
      "screws_154.png\n",
      "screws_155.png\n",
      "screws_159.png\n",
      "screws_160.png\n",
      "screws_163.png\n",
      "screws_164.png\n",
      "screws_165.png\n",
      "screws_166.png\n",
      "screws_167.png\n",
      "screws_168.png\n",
      "screws_170.png\n",
      "screws_171.png\n",
      "screws_173.png\n",
      "screws_175.png\n",
      "screws_176.png\n",
      "screws_178.png\n",
      "screws_179.png\n",
      "screws_181.png\n",
      "screws_182.png\n",
      "screws_183.png\n",
      "screws_185.png\n",
      "screws_186.png\n",
      "screws_187.png\n",
      "screws_188.png\n",
      "screws_189.png\n",
      "screws_190.png\n",
      "screws_191.png\n",
      "screws_192.png\n",
      "screws_193.png\n",
      "screws_194.png\n",
      "screws_196.png\n",
      "screws_197.png\n",
      "screws_198.png\n",
      "screws_199.png\n",
      "screws_201.png\n",
      "screws_205.png\n",
      "screws_206.png\n",
      "screws_207.png\n",
      "screws_209.png\n",
      "screws_211.png\n",
      "screws_214.png\n",
      "screws_215.png\n",
      "screws_216.png\n",
      "screws_218.png\n",
      "screws_221.png\n",
      "screws_223.png\n",
      "screws_224.png\n",
      "screws_228.png\n",
      "screws_229.png\n",
      "screws_230.png\n",
      "screws_232.png\n",
      "screws_233.png\n",
      "screws_235.png\n",
      "screws_236.png\n",
      "screws_237.png\n",
      "screws_239.png\n",
      "screws_240.png\n",
      "screws_241.png\n",
      "screws_243.png\n",
      "screws_244.png\n",
      "screws_248.png\n",
      "screws_250.png\n",
      "screws_251.png\n",
      "screws_253.png\n",
      "screws_254.png\n",
      "screws_255.png\n",
      "screws_256.png\n",
      "screws_257.png\n",
      "screws_261.png\n",
      "screws_263.png\n",
      "screws_265.png\n",
      "screws_266.png\n",
      "screws_268.png\n",
      "screws_269.png\n",
      "screws_270.png\n",
      "screws_271.png\n",
      "screws_272.png\n",
      "screws_275.png\n",
      "screws_276.png\n",
      "screws_278.png\n",
      "screws_283.png\n",
      "screws_284.png\n",
      "screws_286.png\n",
      "screws_287.png\n",
      "screws_288.png\n",
      "screws_290.png\n",
      "screws_291.png\n",
      "screws_292.png\n",
      "screws_293.png\n",
      "screws_295.png\n",
      "screws_296.png\n",
      "screws_297.png\n",
      "screws_299.png\n",
      "screws_300.png\n",
      "screws_301.png\n",
      "screws_303.png\n",
      "screws_304.png\n",
      "screws_306.png\n",
      "screws_307.png\n",
      "screws_308.png\n",
      "screws_309.png\n",
      "screws_311.png\n",
      "screws_314.png\n",
      "screws_315.png\n",
      "screws_316.png\n",
      "screws_318.png\n",
      "screws_319.png\n",
      "screws_320.png\n",
      "screws_322.png\n",
      "screws_324.png\n",
      "screws_325.png\n",
      "screws_326.png\n",
      "screws_327.png\n",
      "screws_328.png\n",
      "screws_329.png\n",
      "screws_332.png\n",
      "screws_333.png\n",
      "screws_334.png\n",
      "screws_335.png\n",
      "screws_336.png\n",
      "screws_339.png\n",
      "screws_340.png\n",
      "screws_341.png\n",
      "screws_342.png\n",
      "screws_344.png\n",
      "screws_345.png\n",
      "screws_346.png\n",
      "screws_347.png\n",
      "screws_348.png\n",
      "screws_350.png\n",
      "screws_351.png\n",
      "screws_352.png\n",
      "screws_353.png\n",
      "screws_354.png\n",
      "screws_355.png\n",
      "screws_356.png\n",
      "screws_358.png\n",
      "screws_359.png\n",
      "screws_360.png\n",
      "screws_363.png\n",
      "screws_364.png\n",
      "screws_367.png\n",
      "screws_369.png\n",
      "screws_370.png\n",
      "screws_371.png\n",
      "screws_372.png\n",
      "screws_373.png\n",
      "screws_374.png\n",
      "screws_375.png\n",
      "screws_376.png\n",
      "screws_377.png\n",
      "screws_379.png\n",
      "screws_380.png\n",
      "screws_381.png\n",
      "screws_383.png\n",
      "screws_384.png\n",
      "Working on val data!\n",
      "screws_001.png\n",
      "screws_010.png\n",
      "screws_015.png\n",
      "screws_023.png\n",
      "screws_027.png\n",
      "screws_046.png\n",
      "screws_051.png\n",
      "screws_056.png\n",
      "screws_058.png\n",
      "screws_059.png\n",
      "screws_078.png\n",
      "screws_089.png\n",
      "screws_098.png\n",
      "screws_099.png\n",
      "screws_105.png\n",
      "screws_110.png\n",
      "screws_111.png\n",
      "screws_129.png\n",
      "screws_130.png\n",
      "screws_131.png\n",
      "screws_142.png\n",
      "screws_145.png\n",
      "screws_156.png\n",
      "screws_172.png\n",
      "screws_177.png\n",
      "screws_184.png\n",
      "screws_195.png\n",
      "screws_202.png\n",
      "screws_203.png\n",
      "screws_210.png\n",
      "screws_212.png\n",
      "screws_213.png\n",
      "screws_217.png\n",
      "screws_222.png\n",
      "screws_226.png\n",
      "screws_227.png\n",
      "screws_234.png\n",
      "screws_247.png\n",
      "screws_258.png\n",
      "screws_259.png\n",
      "screws_262.png\n",
      "screws_264.png\n",
      "screws_277.png\n",
      "screws_285.png\n",
      "screws_302.png\n",
      "screws_312.png\n",
      "screws_313.png\n",
      "screws_321.png\n",
      "screws_337.png\n",
      "screws_338.png\n",
      "screws_343.png\n",
      "screws_361.png\n",
      "screws_365.png\n",
      "screws_368.png\n",
      "screws_382.png\n",
      "Working on test data!\n",
      "screws_006.png\n",
      "screws_017.png\n",
      "screws_022.png\n",
      "screws_042.png\n",
      "screws_044.png\n",
      "screws_045.png\n",
      "screws_064.png\n",
      "screws_065.png\n",
      "screws_079.png\n",
      "screws_096.png\n",
      "screws_102.png\n",
      "screws_106.png\n",
      "screws_108.png\n",
      "screws_126.png\n",
      "screws_136.png\n",
      "screws_140.png\n",
      "screws_151.png\n",
      "screws_152.png\n",
      "screws_157.png\n",
      "screws_158.png\n",
      "screws_161.png\n",
      "screws_162.png\n",
      "screws_169.png\n",
      "screws_174.png\n",
      "screws_180.png\n",
      "screws_200.png\n",
      "screws_204.png\n",
      "screws_208.png\n",
      "screws_219.png\n",
      "screws_220.png\n",
      "screws_225.png\n",
      "screws_231.png\n",
      "screws_238.png\n",
      "screws_242.png\n",
      "screws_245.png\n",
      "screws_246.png\n",
      "screws_249.png\n",
      "screws_252.png\n",
      "screws_260.png\n",
      "screws_267.png\n",
      "screws_273.png\n",
      "screws_274.png\n",
      "screws_279.png\n",
      "screws_280.png\n",
      "screws_281.png\n",
      "screws_282.png\n",
      "screws_289.png\n",
      "screws_294.png\n",
      "screws_298.png\n",
      "screws_305.png\n",
      "screws_310.png\n",
      "screws_317.png\n",
      "screws_323.png\n",
      "screws_330.png\n",
      "screws_331.png\n",
      "screws_349.png\n",
      "screws_357.png\n",
      "screws_362.png\n",
      "screws_366.png\n",
      "screws_378.png\n",
      "Saved 4427 files!\n"
     ]
    }
   ],
   "source": [
    "annotations = []\n",
    "for key in data.keys():\n",
    "    print(f\"Working on {key} data!\")\n",
    "    train_data = CategoricalDataGen(data_name=key, \n",
    "                                    coco_obj=data,\n",
    "                                    image_path=\"./data/images/\",\n",
    "                                    target_size=target_size)\n",
    "\n",
    "    img_data = train_data.lookup['img_data']\n",
    "    boxes = train_data.lookup['annotations']\n",
    "    for img in img_data:\n",
    "        print(img['file_name'])\n",
    "        file_name = img['file_name']\n",
    "        id = img['id']\n",
    "        h = img['height']\n",
    "        w = img['width']\n",
    "        for idx in boxes:\n",
    "            if idx['image_id'] == id:\n",
    "                bbox, _, _ = process_img_annotations(idx['bbox'])\n",
    "                y, x, h, w = convert_points(np.asarray(bbox, dtype=np.float32))\n",
    "                category = int(idx['category_id']) - 1\n",
    "                annotations.append((f\"./data/yolo_v3/obj/{file_name[:-3]}txt\", f\"{category} {y:.6f} {x:.6f} {h:.6f} {w:.6f}\\n\"))\n",
    "                # print(annotations)\n",
    "\n",
    "    # for img in img_data:\n",
    "    #     with open(f\"data/yolo_v3/{key}.txt\", 'a') as file:\n",
    "    #         file.write(f\"data/obj/{img['file_name']}\\n\")\n",
    "\n",
    "count = 0\n",
    "for obj in annotations:\n",
    "    with open(f'{obj[0]}', 'a') as file:\n",
    "        file.write(obj[1])\n",
    "    count += 1\n",
    "print(f\"Saved {count} files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5245da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotations[0])\n",
    "# test_set = [x[1].split() for x in annotations[:16]]\n",
    "# test_set = [[float(y) for y in x[1:]] for x in test_set]\n",
    "# test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f650f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_em(data):\n",
    "    result = np.empty((0,5), dtype=np.float32)\n",
    "    for key in data.keys():\n",
    "        print(f\"Working on {key} data!\")\n",
    "        train_data = CategoricalDataGen(data_name=key, \n",
    "                                        coco_obj=data,\n",
    "                                        image_path=\"./data/images/\",\n",
    "                                        target_size=target_size)\n",
    "\n",
    "        img_data = train_data.lookup['img_data']\n",
    "        boxes = train_data.lookup['annotations']\n",
    "        for img in img_data:\n",
    "            file_name = img['file_name']\n",
    "            id = img['id']\n",
    "            h = img['height']\n",
    "            w = img['width']\n",
    "            for idx in boxes:\n",
    "                if idx['image_id'] == id:\n",
    "                    bbox, _, _ = process_img_annotations(idx['bbox'])\n",
    "                    bbox = np.asarray(convert_points(bbox), dtype=np.float32)\n",
    "                    bbox = np.reshape(bbox, (1, 4))\n",
    "                    cat = np.reshape(np.array([idx['category_id']]), (1, 1))\n",
    "                    result = np.append(result, np.concatenate((cat, bbox), axis=-1), axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24496400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on train data!\n",
      "Working on val data!\n",
      "Working on test data!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4427, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = get_em(data)\n",
    "bboxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "536c5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CategoricalDataGen(data_name=\"train\", coco_obj=data, image_path=\"./data/images/\", target_size=(384, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd700ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = train_data.get_labels(divs=(9, 12), num_boxes=3, num_classes=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c491d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, xdiv, ydiv, _ = training_labels.shape\n",
    "box_cutter = BoundingBox_Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae7fa02",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m box_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(training_labels, [batch \u001b[38;5;241m*\u001b[39m xdiv \u001b[38;5;241m*\u001b[39m ydiv, \u001b[38;5;241m19\u001b[39m])[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m14\u001b[39m:]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m x, y \u001b[38;5;241m=\u001b[39m box_labels[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], box_labels[:, :\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m w, h \u001b[38;5;241m=\u001b[39m box_labels[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m3\u001b[39m], box_labels[:, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "box_labels = tf.reshape(training_labels, [batch * xdiv * ydiv, 19])[..., 14:].numpy()\n",
    "x, y = box_labels[:, 0:1], box_labels[:, :1]\n",
    "w, h = box_labels[:, 2:3], box_labels[:, 3:4]\n",
    "box_labels[:, 0:2] = [384/2, 512/2]\n",
    "box_labels[:, 0:1] = x - w/2\n",
    "box_labels[:, 1:2] = y - h/2\n",
    "box_labels[:, 4:] = -1 * (box_labels[:, 4:] - np.pi)\n",
    "\n",
    "mask_labels = tf.cast(tf.reduce_sum(box_labels, axis=-1) > .001, dtype=tf.bool)\n",
    "box_labels = tf.boolean_mask(box_labels, mask_labels, axis=0).numpy()\n",
    "\n",
    "clusters = KMeans(n_clusters=9, max_iter=100, random_state=1)\n",
    "clusters.fit(box_labels)\n",
    "\n",
    "cls = clusters.predict(box_labels)\n",
    "cls = np.expand_dims(cls, axis=-1)\n",
    "\n",
    "centroid_locations = []\n",
    "for idx in range(13):\n",
    "    filter = tf.where(tf.equal(cls, idx),\n",
    "                             box_labels,\n",
    "                             np.zeros(box_labels.shape, dtype=np.float32))\n",
    "    mask = tf.cast(tf.abs(tf.reduce_sum(filter, axis=-1)) > .001, dtype=tf.float32)\n",
    "    average = tf.reduce_sum(filter, axis=0) / tf.reduce_sum(mask, axis=0)\n",
    "    centroid_locations.append(average.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e878617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Animation size has reached 21047143 bytes, exceeding the limit of 20971520.0. If you're sure you want a larger animation embedded, set the animation.embed_limit rc parameter to a larger value (in MB). This and further frames will be dropped.\n"
     ]
    }
   ],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.set(\n",
    "        xlim=[0, 512],\n",
    "        ylim=[0, 384]\n",
    "        )\n",
    "pick = np.random.choice\n",
    "color = [\"tomato\", \"springgreen\", \"orange\", \"deepskyblue\", \"tab:purple\"]\n",
    "knudge = 512 / 12\n",
    "start = np.array([knudge/2, knudge/2])\n",
    "\n",
    "def animation(i):\n",
    "    ax.axis('off')\n",
    "    v, u = divmod(i, 12)\n",
    "    bump = np.array([u * knudge, v * knudge]) \n",
    "    x, y = start + bump\n",
    "    ax.add_patch(Circle((x, y), 2, fill=True, facecolor='gray', alpha=.6))\n",
    "    anchors = np.random.choice(range(0, 12, 1), 4)\n",
    "    for idx in anchors:\n",
    "        _, _, w, h, a = centroid_locations[idx]\n",
    "    # for box in centroid_locations:\n",
    "    #     _, _, w, h, a = box\n",
    "        ax.add_patch(Rectangle((x-w/2, y-h/2), w, h, angle=a*180/np.pi, rotation_point=\"center\", fill=None, lw=.5, edgecolor=pick(color)))\n",
    "ax.axis('off')\n",
    "pillow = PillowWriter(fps=24)\n",
    "anim = FuncAnimation(fig, animation, frames=9 * 12, cache_frame_data=False)\n",
    "anim.save(\"./images/anchor_anim.gif\", writer=pillow)\n",
    "HTML(anim.to_jshtml(fps=24))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e70e6d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "points = []\n",
    "knudge = 512 / 12\n",
    "start = np.array([knudge/2, knudge/2])\n",
    "for cell in range(12 * 9):\n",
    "    v, u = divmod(cell, 12)\n",
    "    points.append(start + [u*knudge, v*knudge])\n",
    "x, y = [[x for x, y in points],\n",
    "        [y for x, y in points]]\n",
    "print(x[:10])\n",
    "plt.scatter(x, y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,auto:percent",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
