{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Section"
      ],
      "metadata": {
        "id": "HOpwTsbfF6vJ"
      },
      "id": "HOpwTsbfF6vJ"
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf /content/screw.tar"
      ],
      "metadata": {
        "id": "LpFa4gfCgej5"
      },
      "id": "LpFa4gfCgej5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade matplotlib"
      ],
      "metadata": {
        "id": "ljX1wm1q8I3n"
      },
      "id": "ljX1wm1q8I3n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "i38lqbvHi3UO"
      },
      "id": "i38lqbvHi3UO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/gdrive/MyDrive/colab_output/images\""
      ],
      "metadata": {
        "id": "MPxeigXbjhMx"
      },
      "id": "MPxeigXbjhMx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a1c51be",
      "metadata": {
        "scrolled": true,
        "id": "3a1c51be"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import pprint as pp\n",
        "from glob import glob, iglob\n",
        "from PIL import Image, ImageFilter\n",
        "from typing import List, Union, Tuple, BinaryIO\n",
        "\n",
        "from keras.api._v2.keras.layers import Conv3DTranspose\n",
        "\n",
        "pp.PrettyPrinter(indent=4)\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential, layers, losses, metrics\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data init"
      ],
      "metadata": {
        "id": "I0J5dLArt4mk"
      },
      "id": "I0J5dLArt4mk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d533b6fb",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "d533b6fb"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/train/\"\n",
        "train_dir = pathlib.Path(train_dir)\n",
        "test_dir = \"/content/test/\"\n",
        "test_dir = pathlib.Path(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b6e80a",
      "metadata": {
        "scrolled": false,
        "id": "66b6e80a"
      },
      "outputs": [],
      "source": [
        "batch_size, img_height, img_width = (320, 256, 256)\n",
        "x_train = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                      seed=142,\n",
        "                                                      image_size=(img_height, img_width),\n",
        "                                                      color_mode='grayscale',\n",
        "                                                      batch_size=None,\n",
        "                                                      shuffle=False,\n",
        "                                                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ac71af",
      "metadata": {
        "id": "82ac71af"
      },
      "outputs": [],
      "source": [
        "# test_batch = 160\n",
        "x_test = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
        "                                                     seed=142,\n",
        "                                                     image_size=(img_height, img_width),\n",
        "                                                     batch_size=None,\n",
        "                                                     shuffle=False,\n",
        "                                                     color_mode='grayscale',\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1283130f",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "1283130f"
      },
      "outputs": [],
      "source": [
        "train_classes = x_train.class_names\n",
        "train_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d3e625",
      "metadata": {
        "id": "d5d3e625"
      },
      "outputs": [],
      "source": [
        "x_2_train_np = np.array(list(map(lambda x : x[0], x_train.as_numpy_iterator())), 'float16')\n",
        "x_2_train_final = x_2_train_np.astype('float16') / 255\n",
        "x_2_train_final = x_2_train_final.reshape(320, 256, 256, 1)\n",
        "x_2_train_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48cee834",
      "metadata": {
        "id": "48cee834"
      },
      "outputs": [],
      "source": [
        "x_2_test_np = np.array(list(map(lambda x : x[0], x_test.as_numpy_iterator())), 'float16')\n",
        "x_2_test_final = x_2_test_np.astype('float16') / 255\n",
        "x_2_test_final = x_2_test_final.reshape(160, 256, 256, 1)\n",
        "x_2_test_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Metrics"
      ],
      "metadata": {
        "id": "hZc0-vUSuRS5"
      },
      "id": "hZc0-vUSuRS5"
    },
    {
      "cell_type": "code",
      "source": [
        "class ssim_metric(tf.keras.metrics.Metric):\n",
        "  def __init__(self, name=\"ssim_metric\", **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "    self.ssim = self.add_weight(name=\"ssim\", initializer=\"zeros\")\n",
        "    self.total_samples = self.add_weight(name=\"total_samples\",\n",
        "                                         initializer=\"zeros\",\n",
        "                                         dtype=\"int32\")\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    ssim_metric = tf.image.ssim(y_true, y_pred, max_val=1)\n",
        "    ssim_metric = ssim[0].numpy()\n",
        "    self.ssim.assign_add(ssim_loss)\n",
        "\n",
        "  def result(self):\n",
        "    return tf.subtract(self.ssim, 1)\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.ssim.assign(0.)"
      ],
      "metadata": {
        "id": "B4RpPrhUD99p"
      },
      "id": "B4RpPrhUD99p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ssim_loss(tf.keras.losses.Loss):\n",
        "  @tf.function\n",
        "  def call(self, y_true, y_pred):\n",
        "    ssim_loss = tf.image.ssim(y_true, y_pred, max_val=1)\n",
        "    return tf.subtract(1., ssim_loss)\n"
      ],
      "metadata": {
        "id": "YuxN2DudPJHb"
      },
      "id": "YuxN2DudPJHb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "0ztW3-DpuYte"
      },
      "id": "0ztW3-DpuYte"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics, Loss"
      ],
      "metadata": {
        "id": "MNrDb0VGuj30"
      },
      "id": "MNrDb0VGuj30"
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_block(x, filters, kernel_size=3, reps:int=2, pooling:bool=False, **kwargs):\n",
        "  residual = x\n",
        "  options = {}\n",
        "  if kwargs:\n",
        "    options.update(**kwargs)\n",
        "  for rep in range(reps):\n",
        "    if not rep:\n",
        "      options.update({'strides': 2})\n",
        "    else:\n",
        "      options['strides'] = 1\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(filters, kernel_size, padding=\"same\", use_bias=False, **options)(x)\n",
        "  \n",
        "  if pooling:\n",
        "    x = layers.MaxPooling2D(kernel_size, strides=2, padding=\"same\")(x)\n",
        "    # residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
        "  # elif filters != residual.shape[-1]:\n",
        "  #   residual = layers.Conv2D(filters, 1)(residual)\n",
        "  \n",
        "  # x = layers.add([x, residual])\n",
        "  return x"
      ],
      "metadata": {
        "id": "rLMNtvOPAw6N"
      },
      "id": "rLMNtvOPAw6N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_T_block(x, filters, kernel_size=3, reps:int=2, **kwargs):\n",
        "  residual = x\n",
        "  options = {'strides': 2}\n",
        "  if kwargs:\n",
        "    options.update(**kwargs)\n",
        "  for rep in range(reps):\n",
        "    if not rep:\n",
        "      options.update({'strides': 2})\n",
        "    else:\n",
        "      options['strides'] = 1\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.Conv2DTranspose(filters, kernel_size, padding=\"same\", use_bias=False, **options)(x)\n",
        "  \n",
        "  # residual = layers.Conv2D(filters, 1)(residual)\n",
        "  \n",
        "  # x = layers.add([x, residual])\n",
        "  return x"
      ],
      "metadata": {
        "id": "EycVuJucLxQc"
      },
      "id": "EycVuJucLxQc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition (clf_model init)"
      ],
      "metadata": {
        "id": "3aKJHpWqupC6"
      },
      "id": "3aKJHpWqupC6"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(input_shape, filter_blocks:List, rescaling:bool=False, **kwargs):\n",
        "  inputs = tf.keras.Input(shape=input_shape)\n",
        "  if rescaling:\n",
        "    x = layers.Rescaling(1./255)(inputs)\n",
        "    x = layers.Conv2D(filter_blocks[0], kernel_size=5, padding='same', use_bias=False)(x)\n",
        "  else:\n",
        "    x = layers.Conv2D(filter_blocks[0], kernel_size=5, padding='same', use_bias=False)(inputs)\n",
        "  \n",
        "  for block in filter_blocks:\n",
        "    x = conv2d_block(x, block, **kwargs)\n",
        "  \n",
        "  r_filter_blocks = reversed(filter_blocks)\n",
        "  for t_block in r_filter_blocks:\n",
        "    x = conv2d_T_block(x, t_block, **kwargs)\n",
        "\n",
        "  outputs = layers.Conv2D(1, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "olkcDzKWEwQs"
      },
      "id": "olkcDzKWEwQs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = [32, 64, 128, 256, 512]\n",
        "input_shape = x_2_train_final.shape[1:-1] + (1,)\n",
        "print(input_shape)\n",
        "clf_model = get_model(input_shape=input_shape, filter_blocks=filters)\n",
        "clf_model.summary()"
      ],
      "metadata": {
        "id": "DclwdwoeMvqA"
      },
      "id": "DclwdwoeMvqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Compile, Fit"
      ],
      "metadata": {
        "id": "eoarnjl0u6Tl"
      },
      "id": "eoarnjl0u6Tl"
    },
    {
      "cell_type": "code",
      "source": [
        "clf_model.compile(optimizer=\"adam\", loss=ssim_loss(), metrics=[\"MeanSquaredError\", \"Poisson\"])"
      ],
      "metadata": {
        "id": "VscDNqOyUmIn"
      },
      "id": "VscDNqOyUmIn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = clf_model.fit(x_2_train_final, x_2_train_final, \n",
        "                    epochs=28,\n",
        "                    batch_size=32,\n",
        "                    # callbacks = callbacks,\n",
        "                    validation_data=(x_2_test_final, x_2_test_final))"
      ],
      "metadata": {
        "id": "RDPnMbm0U6kB"
      },
      "id": "RDPnMbm0U6kB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# History Graphing"
      ],
      "metadata": {
        "id": "UN8dPpTAvDHW"
      },
      "id": "UN8dPpTAvDHW"
    },
    {
      "cell_type": "code",
      "source": [
        "num = len(history.history.keys()) / 2\n",
        "metric = (key for key in history.history.keys())\n",
        "fig, ax = plt.subplots(2, 2, figsize=(8, 1.5*num))\n",
        "for j in range(2):\n",
        "  for i in range(int(num/2)):\n",
        "    this_metric = next(metric)\n",
        "    ax[i, j].plot(history.history[this_metric])\n",
        "    ax[i, j].plot(history.history[f\"val_{this_metric}\"])\n",
        "    ax[i, j].set_title(f'{this_metric}'.title())\n",
        "    ax[i, j].set(xlabel=\"Epochs\", ylabel=\"Loss\")\n",
        "plt.savefig(f\"{image_path}/ssim_output_graph_{run_count:03d}.png\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xYPsl2YV1pOp"
      },
      "id": "xYPsl2YV1pOp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect Model Image Output "
      ],
      "metadata": {
        "id": "yhbTkeNivO_g"
      },
      "id": "yhbTkeNivO_g"
    },
    {
      "cell_type": "code",
      "source": [
        "def img_gen(path_list, rand_samp:bool=False):\n",
        "  if rand_samp:\n",
        "    ind = np.random.randint(0, len(path_list) - 1)\n",
        "  path = path_list[ind]\n",
        "  label = os.path.dirname(path)\n",
        "  label = label.split('/')[-1]\n",
        "  dense = Image.open(path)\n",
        "  dense = np.asarray(dense.resize((256, 256)), dtype=np.float32)\n",
        "  dense = dense / 255\n",
        "  dense = dense.reshape((1, 256, 256, 1))\n",
        "  yield dense, label\n"
      ],
      "metadata": {
        "id": "0eG3bb6Z-vQe"
      },
      "id": "0eG3bb6Z-vQe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_c = 9"
      ],
      "metadata": {
        "id": "zZBI4ddYDex9"
      },
      "id": "zZBI4ddYDex9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
        "for i in range(10):\n",
        "  img_paths = glob(\"/content/train/**/*.png\")\n",
        "  img_in, label = next(img_gen(img_paths, rand_samp=True))\n",
        "  img_out = clf_model.predict(img_in)\n",
        "  error = tf.image.ssim(tf.sqrt(img_in**2),tf.sqrt(img_out**2), max_val=1)\n",
        "  print(error[0].numpy())\n",
        "  ax1 = ax[0, i]\n",
        "  ax1.imshow(img_in[0,:,:,0], cmap='gray')\n",
        "  ax1.axis('off')\n",
        "  ax2 = ax[1, i]\n",
        "  ax2.imshow(img_out[0,:,:,0], cmap='gray')\n",
        "  ax1.set_title(label)\n",
        "  ax2.set_title(f\"{1 - error[0].numpy():.4f}\")\n",
        "  ax2.axis('off')\n",
        "fig.tight_layout()\n",
        "plt.savefig(f\"{image_path}/ssim_output_{img_c:03d}.png\")\n",
        "img_c += 1\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TngR0xmIkEoO"
      },
      "id": "TngR0xmIkEoO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Prediction Funcions"
      ],
      "metadata": {
        "id": "iDlXUgAsvbvo"
      },
      "id": "iDlXUgAsvbvo"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img(path):\n",
        "  dense = Image.open(path)\n",
        "  dense = np.asarray(dense.resize((256, 256)), dtype=np.float32)\n",
        "  dense = dense / 255\n",
        "  dense = dense.reshape((1, 256, 256, 1))\n",
        "  return dense, label\n",
        "\n",
        "\n",
        "def get_distributions(model):\n",
        "  result = []\n",
        "  for path in iglob(\"/content/test/**/*.png\"):\n",
        "    img, label = get_img(path)\n",
        "    pred = model.predict(img)\n",
        "    mse = np.abs(np.mean(img**2 - pred**2))\n",
        "    ssim = tf.image.ssim(img, pred, max_val=1)\n",
        "    ssim = 1 - ssim[0].numpy()\n",
        "    result.append([ssim, mse, label])\n",
        "  return result"
      ],
      "metadata": {
        "id": "gvQ7_H8smd3G"
      },
      "id": "gvQ7_H8smd3G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Model Predictions"
      ],
      "metadata": {
        "id": "r46D6pWMvjar"
      },
      "id": "r46D6pWMvjar"
    },
    {
      "cell_type": "code",
      "source": [
        "loss_distributions = get_distributions(clf_model)"
      ],
      "metadata": {
        "id": "WwxPQrTiuyy6"
      },
      "id": "WwxPQrTiuyy6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = np.asarray(loss_distributions)\n",
        "print(losses.shape)\n",
        "losses = losses[:,:2].astype(np.float32)\n",
        "losses_df.info()\n"
      ],
      "metadata": {
        "id": "eBhxiz7ivCsT"
      },
      "id": "eBhxiz7ivCsT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graphing Prediction Loss"
      ],
      "metadata": {
        "id": "TWM4YaPHvqeh"
      },
      "id": "TWM4YaPHvqeh"
    },
    {
      "cell_type": "code",
      "source": [
        "fig , ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "hist_x, hist_y = np.histogram(losses[:40, 0], bins=12)\n",
        "ax[0].stairs(hist_x, hist_y, hatch=('...'))\n",
        "hist_w, hist_v = np.histogram(losses[40:, 0], bins=20)\n",
        "ax[0].stairs(hist_w, hist_v, hatch=('...'))\n",
        "hist_x, hist_y = np.histogram(losses[:40, 1], bins=12)\n",
        "ax[1].stairs(hist_x, hist_y, hatch=('...'))\n",
        "hist_w, hist_v = np.histogram(losses[40:, 1], bins=20)\n",
        "ax[1].stairs(hist_w, hist_v, hatch=('...'))\n",
        "\n",
        "# plt.stairs(norm_y, norm_x, hatch=('...'), label=\"Normal\")\n"
      ],
      "metadata": {
        "id": "tMgHc1_NxI_h"
      },
      "id": "tMgHc1_NxI_h",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "formats": "ipynb,auto:percent",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}